# üìä An√°lisis Predicci√≥n vs Realidad - USA Hybrid Clean V1

## Resumen Ejecutivo

Se han generado **an√°lisis completos** de predicci√≥n vs realidad para los modelos:
- **`return_model_H3`**: Predice retorno a 3 d√≠as (`y_hat` vs `y_H3`)
- **`prob_win_clean`**: Predice probabilidad de ganancia (`prob_win`)

### üìà Hallazgos Principales

| M√©trica | Valor | Interpretaci√≥n |
|---------|-------|-----------------|
| **MAE** | 0.0518 | Error promedio muy bajo ‚úì |
| **RMSE** | 0.0685 | Consistente |
| **Directional Accuracy** | 48.81% | **‚ö†Ô∏è Apenas mejor que aleatorio** |
| **Brier Score (prob_win)** | 0.2827 | Razonablemente bien calibrado |
| **Win Rate Real** | 54.61% | Ligeramente positivo |
| **Prob Predicha** | 42.16% | Sesgo conservador (-12.45%) |

---

## üìÅ Archivos Generados

### 1. Scripts Python

#### `analysis_pred_vs_real.py`
**Qu√© hace:** An√°lisis completo de predicci√≥n vs realidad
- Carga `forecast_signals.csv`
- Calcula MAE, RMSE, MAPE, directional accuracy
- Genera **10 gr√°ficas** (5 globales + 5 por ticker top)
- Imprime m√©tricas por ticker

**Usar:**
```bash
python analysis_pred_vs_real.py
```

**Salida:** 
- `outputs/analysis/01_pred_vs_real_*.png` - L√≠neas (predicci√≥n vs real)
- `outputs/analysis/02_error_timeseries_*.png` - Error absoluto
- `outputs/analysis/03_error_band_*.png` - Banda de confianza
- `outputs/analysis/04_scatter_*.png` - Scatter plot
- `outputs/analysis/05_calibration_*.png` - Curva de calibraci√≥n

---

#### `analysis_trading_results.py`
**Qu√© hace:** An√°lisis de trades ejecutados (equity curve)
- Carga `outputs/equity_curve.csv`
- Calcula win rate, PnL total, profit factor
- Genera **4 gr√°ficas** de trading

**Usar:**
```bash
python analysis_trading_results.py
```

**Salida:**
- `outputs/analysis/06_pnl_timeseries.png` - PnL por trade + acumulado
- `outputs/analysis/07_pnl_distribution.png` - Histograma ganancias/p√©rdidas
- `outputs/analysis/08_pnl_by_ticker.png` - Box plot por ticker
- `outputs/analysis/09_win_rate_by_ticker.png` - Win rate y avg PnL

---

### 2. Dashboard Interactivo

#### `analysis_dashboard.html`
**Qu√© es:** Visualizador web con todas las gr√°ficas y m√©tricas

**Usar:**
```bash
# Opci√≥n 1: Servidor local
python serve_analysis_dashboard.py
# Luego abre: http://localhost:8765/analysis_dashboard.html

# Opci√≥n 2: Abrir directo
# Windows: start analysis_dashboard.html
# Mac/Linux: open analysis_dashboard.html
```

**Pesta√±as disponibles:**
1. üìà **Resumen** - KPIs principales en tarjetas
2. üìâ **Regresi√≥n** - Gr√°ficas de predicci√≥n vs real
3. üìä **Probabilidad** - Curvas de calibraci√≥n
4. üí∞ **Trading** - Resultados de equity curve
5. üí° **Interpretaci√≥n** - An√°lisis y recomendaciones

---

## üéØ Gu√≠a R√°pida de M√©tricas

### **Regresi√≥n (Modelo de Retorno)**

```python
# En tu CSV tienes:
# y_H3    = retorno real a 3 d√≠as
# y_hat   = predicci√≥n del modelo

# M√©tricas calculadas:
MAE     = promedio(|y_true - y_pred|)      # 0.0518
RMSE    = sqrt(promedio((y_true - y_pred)¬≤)) # 0.0685
MAPE    = promedio(|error| / |y_true|) * 100 # 5.7M% (cuidado con divisi√≥n por cero)

# Directional Accuracy
dir_acc = % de veces que sign(y_true) == sign(y_pred)  # 48.81%
```

### **Probabilidad (Brier Score)**

```python
# En tu CSV tienes:
# prob_win = probabilidad predicha
# y_H3     = retorno real

# Conversi√≥n a binario:
y_true_binary = 1 si y_H3 > 0, sino 0   # ¬øganamos?

# Brier Score (error cuadr√°tico medio de probabilidades)
brier = promedio((prob_win - y_true_binary)¬≤)  # 0.2827

# Calibraci√≥n: ¬øson las probs confiables?
# Ideal = curva en diagonal de 45¬∞
# Real = qu√© frecuencia real corresponde a cada prob predicha
```

### **Trading**

```python
# En equity_curve.csv tienes:
# PnL USD = ganancia/p√©rdida por trade
# Exit Reason = por qu√© se cerr√≥

# M√©tricas:
win_rate = % de trades con PnL USD > 0  # 0% (actualmente)
profit_factor = (ganancias totales) / (p√©rdidas totales)  # 0 si no hay ganancias
avg_win = PnL promedio de trades ganadores
avg_loss = PnL promedio de trades perdedores
```

---

## üìä Interpretaci√≥n de Resultados

### ‚úÖ Lo Positivo

1. **MAE muy bajo (0.0518)**: El error promedio en predicci√≥n es peque√±o
2. **Brier Score razonable (0.28)**: prob_win est√° bien calibrado (rango ideal: 0.20-0.30)
3. **Datos suficientes**: 26,640 observaciones (v√°lido estad√≠sticamente)
4. **Diversificaci√≥n**: Funciona en 18 tickers diferentes

### ‚ö†Ô∏è Lo que Preocupa

1. **Directional Accuracy = 48.81%** 
   - Idealmente deber√≠a ser > 52% para ser mejor que aleatorio
   - El modelo NO est√° prediciendo bien si el retorno sube o baja
   - **Implicaci√≥n**: El MAE bajo puede deberse a que el modelo predice todo muy cerca de 0

2. **Sesgo en prob_win = -12.45%**
   - Predice 42% cuando la realidad es 54.61%
   - El modelo es demasiado conservador
   - **Soluci√≥n**: Recalibraci√≥n isot√≥nica

3. **Datos de trading actuales**
   - Solo 4 trades en per√≠odo reciente
   - Win rate 0% (pero per√≠odo muy corto)
   - Esperar m√≠nimo 30-50 trades para validar

---

## üîß Personalizaci√≥n

### Cambiar per√≠odo de an√°lisis

En `analysis_pred_vs_real.py`, l√≠nea donde cargas el CSV:

```python
# Filtrar solo ciertos tickers
df = df[df["ticker"].isin(["AAPL", "MSFT", "NVDA"])]

# Filtrar por fecha
df = df[(df["date"] >= "2025-09-01") & (df["date"] <= "2025-10-31")]

# Filtrar solo trades ganadores
df_wins = df[df["y_H3"] > 0]
```

### Cambiar banda de error

En `plot_error_band()`:

```python
k = 2.0  # Cambiar de 1.0 a 2.0 para banda m√°s ancha (2œÉ)
```

### Agregar m√°s gr√°ficas

Patr√≥n a seguir:

```python
def plot_nueva_grafica(df):
    fig, ax = plt.subplots(figsize=(14, 6))
    # Tu c√≥digo aqu√≠
    plt.savefig(OUTPUTS_DIR / "10_nueva_grafica.png", dpi=150)
    plt.close()
```

---

## üìà Recomendaciones Pr√≥ximos Pasos

### 1. **Inmediato** (Hoy)
- [ ] Revisar directional accuracy: ¬øpor qu√© es ~50%?
- [ ] Analizar distribuci√≥n de y_H3: ¬øhay muchos valores cercanos a 0?
- [ ] Verificar que features sean relevantes

### 2. **Corto plazo** (Esta semana)
- [ ] Recalibrar prob_win (usar `sklearn.calibration.CalibratedClassifierCV`)
- [ ] Esperar a tener m√≠nimo 20 trades ejecutados para validar
- [ ] Analizar por sector: ¬øalguno tiene mejor performance?

### 3. **Mediano plazo** (Este mes)
- [ ] Intentar ensemble de modelos (bagging, stacking)
- [ ] Feature engineering: agregar volatilidad, momentum, correlation
- [ ] An√°lisis de r√©gimen: ¬ømejor performance en ciertos per√≠odos?

### 4. **Validaci√≥n rolling**
- Ejecutar estos scripts **semanalmente** para monitorear degradaci√≥n
- Alertar si directional accuracy cae por debajo de 48%
- Re-entrenar modelos si m√©tricas se degradan 10%+

---

## üíª Requisitos

```bash
# Instalar (si no est√° hecho):
pip install pandas numpy matplotlib seaborn scikit-learn

# Verificar:
python -c "import pandas, numpy, matplotlib, seaborn, sklearn; print('‚úì OK')"
```

---

## üìû Troubleshooting

### Error: "No encontrado: forecast_signals.csv"
- Verifica que exista: `reports/forecast/2025-11/forecast_signals.csv`
- Si no, ejecuta antes: el pipeline de inferencia (`infer_and_gate.py`)

### Error: "ModuleNotFoundError: No module named 'seaborn'"
```bash
pip install seaborn
```

### Las gr√°ficas se ven blancas
- Aseg√∫rate que el directorio `outputs/analysis/` existe
- El script deber√≠a crearlo autom√°ticamente, pero puedes crear manualmente

### Dashboard no carga im√°genes
- Verifica que `outputs/analysis/*.png` exista y tenga los nombres exactos
- Abre developer tools (F12) en navegador para ver errores

---

## üìù Ejemplo de Uso Completo

```bash
# 1. Ejecutar an√°lisis
python analysis_pred_vs_real.py
python analysis_trading_results.py

# 2. Servir dashboard
python serve_analysis_dashboard.py

# 3. Abrir navegador
# http://localhost:8765/analysis_dashboard.html

# 4. Explorar pesta√±as
# - Resumen: ver KPIs
# - Regresi√≥n: ver si modelo predice bien direcci√≥n
# - Probabilidad: ver si prob_win es confiable
# - Trading: ver PnL
# - Interpretaci√≥n: leer recomendaciones
```

---

## üìö Recursos Adicionales

### M√©tricas de Regresi√≥n
- **MAE**: M√°s interpretable (misma unidad que y)
- **RMSE**: Penaliza outliers m√°s
- **MAPE**: Porcentual, pero cuidado con divisiones por cero

### Calibraci√≥n
- **Brier Score < 0.25**: Bien calibrado
- **Brier Score 0.25-0.30**: Aceptable
- **Brier Score > 0.35**: Requiere recalibraci√≥n

### Directional Accuracy
- **50%**: Aleatorio puro (no hay skill)
- **52-55%**: Algo de skill
- **> 55%**: Buen modelo de direcci√≥n

---

**Generado:** 12 Enero 2026  
**Autor:** GitHub Copilot  
**Datos:** 2020-01-02 a 2025-10-31 (26,640 observaciones)  
**Modelos:** `return_model_H3.joblib`, `prob_win_clean.joblib`
